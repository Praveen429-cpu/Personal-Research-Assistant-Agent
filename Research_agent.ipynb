{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import openai\n",
        "import time\n",
        "from typing import List, Dict"
      ],
      "metadata": {
        "id": "xPzOJhiTKeWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set your OpenAI API key here\n",
        "openai.api_key = 'your-openai-api-key'"
      ],
      "metadata": {
        "id": "x-z2d6fHKjAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Query Semantic Scholar\n",
        "# -----------------------\n",
        "def search_papers(query: str, limit: int = 5) -> List[Dict]:\n",
        "    url = f\"https://api.semanticscholar.org/graph/v1/paper/search?query={query}&limit={limit}&fields=title,abstract,year,authors,url\"\n",
        "\n",
        "    # Implement a retry mechanism with exponential backoff\n",
        "    for i in range(3):  # Retry up to 3 times\n",
        "        try:\n",
        "            response = requests.get(url)\n",
        "            response.raise_for_status()  # Raise HTTPError for bad responses (4xx or 5xx)\n",
        "            papers = response.json().get('data', [])\n",
        "            return papers\n",
        "        except requests.exceptions.HTTPError as e:\n",
        "            if e.response.status_code == 429:  # If rate limited\n",
        "                wait_time = 2 ** i  # Exponential backoff: 1, 2, 4 seconds\n",
        "                print(f\"Rate limited, retrying in {wait_time} seconds...\")\n",
        "                time.sleep(wait_time)\n",
        "            else:\n",
        "                raise  # Re-raise other HTTP errors\n",
        "\n",
        "    # If all retries fail, raise an exception\n",
        "    raise Exception(\"Failed to retrieve papers after multiple retries.\")"
      ],
      "metadata": {
        "id": "AV-oKXfhKnRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xb7D7KreLYGJ",
        "outputId": "5eac1ae1-fb94-4565-9f65-72c81af2388b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.78.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Summarize Abstracts\n",
        "# -----------------------\n",
        "def summarize_abstracts(papers: List[Dict]) -> str:\n",
        "    abstracts = \"\\n\\n\".join(\n",
        "        [f\"Title: {p['title']}\\nAbstract: {p['abstract']}\" for p in papers if p.get('abstract')]\n",
        "    )\n",
        "\n",
        "    if not abstracts:\n",
        "        return \"No abstracts found to summarize.\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You are a research assistant. Summarize the key trends, findings, and challenges from the following academic paper abstracts:\n",
        "\n",
        "{abstracts}\n",
        "\n",
        "Format the response as:\n",
        "- Key Trends:\n",
        "- Major Findings:\n",
        "- Open Challenges:\n",
        "\"\"\"\n",
        "\n",
        "    # Updated to use openai.Completion.create with the chat format\n",
        "    response = openai.Completion.create(\n",
        "        model=\"gpt-3.5-turbo\",  # or any other suitable chat model\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful academic assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0.5\n",
        "    )\n",
        "    return response['choices'][0]['text'].strip() # Accessing 'text' instead of 'message'"
      ],
      "metadata": {
        "id": "tmfGldiaLSD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Main Pipeline\n",
        "# -----------------------\n",
        "def run_agent(query: str):\n",
        "    print(f\"Searching for papers on: {query}\\n\")\n",
        "    papers = search_papers(query)\n",
        "\n",
        "    for i, paper in enumerate(papers, 1):\n",
        "        print(f\"[{i}] {paper['title']} ({paper['year']})\")\n",
        "        print(f\"    Authors: {', '.join([a['name'] for a in paper['authors']])}\")\n",
        "        print(f\"    URL: {paper['url']}\\n\")\n",
        "\n",
        "    summary = summarize_abstracts(papers)\n",
        "    print(\"\\n===== Coherent Summary =====\\n\")\n",
        "    print(summary)"
      ],
      "metadata": {
        "id": "LQANFwT9Ks6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run Example\n",
        "# -----------------------\n",
        "if __name__ == '__main__':\n",
        "    research_query = input(\"Enter your research query: \")\n",
        "    run_agent(research_query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xu7ZikuoKy7h",
        "outputId": "b0ba702b-a706-4681-a164-64dfbf4d7395"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your research query: research_query\n",
            "Searching for papers on: research_query\n",
            "\n",
            "\n",
            "===== Coherent Summary =====\n",
            "\n",
            "No abstracts found to summarize.\n"
          ]
        }
      ]
    }
  ]
}